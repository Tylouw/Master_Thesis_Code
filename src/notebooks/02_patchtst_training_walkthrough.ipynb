{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# PatchTST — Training & Evaluation Walkthrough + Exercises\n\nThis notebook is built **from your `train_patchtst.py` script**. We'll go from:\nCSV → Dataset → DataLoader → training loop → evaluation → confusion matrix → threshold sweep → session split.\n\n**Goal:** you can explain every step in your meeting and in your thesis defense.\n\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# === Setup ===\nimport os, sys\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\n\nPROJECT_ROOT = Path(\".\").resolve()\nSRC_DIR = PROJECT_ROOT / \"src\"\nif SRC_DIR.exists():\n    sys.path.insert(0, str(SRC_DIR))\nelse:\n    print(\"WARNING: src/ not found. Update SRC_DIR accordingly.\")\n\nfrom patchtst import PatchTSTClassifier, PatchTSTConfig\nfrom train_patchtst import ForceCSVFolderDataset, USE_COLS, LABEL_RE, metrics_from_cm, confusion_matrix_binary_from_logits\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"device:\", device)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) Understanding the dataset object\n\n`ForceCSVFolderDataset` does:\n1. Collect all CSV files recursively\n2. Parse label from filename (`_True.csv` or `_False.csv`)\n3. Read 6 columns\n4. (Optionally) normalize per-sample per-channel\n5. Return `(x, y)` where `x: [L, C]` and `y: scalar`\n\n### Exercise 1.1\nInspect the regex and test it on a few filenames.\n\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# TODO: Exercise 1.1\ntest_names = [\n    \"FERA2025_08_28_14_46_02_True.csv\",\n    \"FERA2025_08_28_16_09_46_False.csv\",\n    \"something_else.csv\",\n]\n\nfor name in test_names:\n    m = LABEL_RE.search(name)\n    print(name, \"->\", m.group(1) if m else None)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2) Load real data (if available) + plot\n\n### Exercise 2.1\nSet `DATA_ROOT` to your dataset folder (project-relative) and load the dataset.\nThen:\n- print number of samples\n- print first file path\n- load first sample and confirm shapes\n\nIf you run this on a machine without the dataset, skip and continue.\n\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# TODO: Exercise 2.1\nDATA_ROOT = \"ForceDataNovo/Old_Fixture\"  # change if needed\n\nif Path(DATA_ROOT).exists():\n    ds = ForceCSVFolderDataset(DATA_ROOT, seq_len=1000, normalize=True)\n    print(\"n_samples:\", len(ds))\n    print(\"first file:\", ds.files[0])\n\n    x, y = ds[0]\n    print(\"x.shape:\", tuple(x.shape), \"y:\", float(y))\nelse:\n    print(\"Dataset not found at:\", DATA_ROOT)\n    ds = None\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Exercise 2.2 (plot one sample)\n\nPlot the 6 channels vs time for one sample.\n- x is `[L, C]`\n- time index is `0..999` (500 Hz for 2 seconds)\n\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# TODO: Exercise 2.2\nif ds is not None:\n    x, y = ds[0]\n    x_np = x.numpy()  # [L, C]\n\n    plt.figure()\n    for i, col in enumerate(USE_COLS):\n        plt.plot(x_np[:, i], label=col)\n    plt.title(f\"One sample | label={int(y.item())}\")\n    plt.legend()\n    plt.show()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3) Session split vs random split (leakage control)\n\nYour folder names look like sessions (dates). A safe evaluation is to hold out entire sessions.\n\n### Exercise 3.1\nCount files per group = `p.parent.name`.\nPrint:\n- number of groups\n- top groups by count\n\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# TODO: Exercise 3.1\nfrom collections import Counter\n\nif ds is not None:\n    groups = [p.parent.name for p in ds.files]\n    print(\"unique groups:\", len(set(groups)))\n    print(\"top groups:\", Counter(groups).most_common(10))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Exercise 3.2\nCreate a session split:\n- choose `val_groups` (e.g. last 2 dates)\n- build `train_idx` and `val_idx`\n- compute and print train/val sizes and class balance\n\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# TODO: Exercise 3.2\nif ds is not None:\n    val_groups = {\"2025_09_08\", \"2025_09_09\"}  # change if needed\n\n    groups = [p.parent.name for p in ds.files]\n    train_idx = [i for i, g in enumerate(groups) if g not in val_groups]\n    val_idx   = [i for i, g in enumerate(groups) if g in val_groups]\n\n    train_ds = torch.utils.data.Subset(ds, train_idx)\n    val_ds   = torch.utils.data.Subset(ds, val_idx)\n\n    def labels_for_indices(indices):\n        return [ForceCSVFolderDataset.label_from_name(ds.files[i].name) for i in indices]\n\n    train_labels = labels_for_indices(train_idx)\n    val_labels   = labels_for_indices(val_idx)\n\n    print(\"train size:\", len(train_ds), \"val size:\", len(val_ds))\n    print(\"train pos:\", sum(train_labels), \"neg:\", len(train_labels)-sum(train_labels))\n    print(\"val   pos:\", sum(val_labels), \"neg:\", len(val_labels)-sum(val_labels))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) DataLoader and batch shapes\n\n### Exercise 4.1\nCreate loaders and inspect one batch:\n- expected batch x shape is `[B, L, C]`\n- expected batch y shape is `[B]`\n\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# TODO: Exercise 4.1\nif ds is not None:\n    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n    xb, yb = next(iter(train_loader))\n    print(\"xb.shape:\", tuple(xb.shape))\n    print(\"yb.shape:\", tuple(yb.shape))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5) Training step: forward → loss → backward → update\n\nYour script uses:\n- `BCEWithLogitsLoss` (binary classification, logits)\n- `AdamW`\n- optional AMP (autocast + GradScaler)\n- optional grad clipping\n\n### Exercise 5.1\nRun *one* training step manually and print:\n- logits stats (mean/std)\n- loss\n- grad norm before/after clipping (optional)\n\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# TODO: Exercise 5.1\nif ds is not None:\n    model_cfg = PatchTSTConfig(\n        num_classes=1,\n        patch_len=25,\n        stride=25,\n        d_model=128,\n        n_heads=8,\n        n_layers=2,\n        d_ff=256,\n        dropout=0.1,\n        channel_independent=True,\n        pooling=\"mean\",\n        fuse=\"mean\",\n    )\n    model = PatchTSTClassifier(model_cfg).to(device)\n    opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n    crit = nn.BCEWithLogitsLoss()\n\n    xb, yb = next(iter(train_loader))\n    xb = xb.to(device)\n    yb = yb.to(device)\n\n    model.train()\n    opt.zero_grad()\n\n    logits = model(xb).squeeze(-1)\n    loss = crit(logits, yb)\n    loss.backward()\n\n    # print gradient norm\n    total_norm = 0.0\n    for p in model.parameters():\n        if p.grad is not None:\n            total_norm += p.grad.data.norm(2).item() ** 2\n    total_norm = total_norm ** 0.5\n\n    opt.step()\n\n    print(\"logits mean/std:\", logits.mean().item(), logits.std().item())\n    print(\"loss:\", loss.item())\n    print(\"grad L2 norm:\", total_norm)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6) Confusion matrix and metrics\n\nGiven logits and labels:\n- probability = sigmoid(logit)\n- prediction = prob >= threshold\n\n### Exercise 6.1\nCompute TP, FP, TN, FN for a batch at threshold 0.5 and compute:\n- precision, recall, F1, specificity\n\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# TODO: Exercise 6.1\nif ds is not None:\n    model.eval()\n    with torch.no_grad():\n        logits = model(xb).squeeze(-1)\n\n    tp, fp, tn, fn = confusion_matrix_binary_from_logits(logits.cpu(), yb.cpu(), thr=0.5)\n    precision, recall, f1, specificity = metrics_from_cm(tp, fp, tn, fn)\n\n    print(f\"TP={tp} FP={fp} TN={tn} FN={fn}\")\n    print(f\"precision={precision:.3f} recall={recall:.3f} f1={f1:.3f} specificity={specificity:.3f}\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7) Threshold sweep (balanced accuracy)\n\nBalanced accuracy = (TPR + TNR)/2 = (recall + specificity)/2\n\n### Exercise 7.1\nOn the validation set:\n1. collect all logits and labels\n2. sweep thresholds\n3. plot balanced accuracy vs threshold\n4. report the best threshold\n\nThis reproduces the logic in your script in an interactive way.\n\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# TODO: Exercise 7.1\nif ds is not None:\n    # collect logits/labels on val set\n    val_loader = torch.utils.data.DataLoader(val_ds, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n\n    model.eval()\n    all_logits = []\n    all_y = []\n    with torch.no_grad():\n        for xb, yb in val_loader:\n            xb = xb.to(device)\n            logits = model(xb).squeeze(-1).cpu()\n            all_logits.append(logits)\n            all_y.append(yb.cpu())\n\n    logits = torch.cat(all_logits)\n    y = torch.cat(all_y)\n\n    probs = torch.sigmoid(logits)\n    thresholds = torch.linspace(0.05, 0.95, steps=19)\n\n    bal_accs = []\n    for thr in thresholds:\n        pred = (probs >= float(thr)).to(torch.int64)\n        y_i = y.to(torch.int64)\n        tp = int(((pred==1)&(y_i==1)).sum())\n        fp = int(((pred==1)&(y_i==0)).sum())\n        tn = int(((pred==0)&(y_i==0)).sum())\n        fn = int(((pred==0)&(y_i==1)).sum())\n        precision, recall, f1, specificity = metrics_from_cm(tp, fp, tn, fn)\n        bal_acc = 0.5*(recall+specificity)\n        bal_accs.append(bal_acc)\n\n    # plot\n    plt.figure()\n    plt.plot([float(t) for t in thresholds], bal_accs, marker=\"o\")\n    plt.xlabel(\"threshold\")\n    plt.ylabel(\"balanced accuracy\")\n    plt.title(\"Balanced accuracy vs threshold\")\n    plt.grid(True)\n    plt.show()\n\n    best_i = int(np.argmax(bal_accs))\n    print(\"best thr:\", float(thresholds[best_i]), \"best bal acc:\", float(bal_accs[best_i]))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 8) End-to-end training (short run)\n\n### Exercise 8.1\nTrain for a few epochs and observe:\n- train loss decreases\n- val balanced accuracy improves\n- best threshold stabilizes as the model gets better\n\nTry:\n- different `patch_len` (10, 25, 50)\n- overlapping patches (`stride < patch_len`)\n- different `d_model` (64 vs 128)\n\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# TODO: Exercise 8.1 (short run)\nif ds is not None:\n    # fresh model for a short run\n    model_cfg = PatchTSTConfig(\n        num_classes=1,\n        patch_len=25,\n        stride=25,\n        d_model=128,\n        n_heads=8,\n        n_layers=4,\n        d_ff=256,\n        dropout=0.1,\n        channel_independent=True,\n        pooling=\"mean\",\n        fuse=\"mean\",\n    )\n    model = PatchTSTClassifier(model_cfg).to(device)\n    opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n    crit = nn.BCEWithLogitsLoss()\n\n    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n    val_loader   = torch.utils.data.DataLoader(val_ds, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n\n    def eval_bal_acc(model):\n        model.eval()\n        all_logits, all_y = [], []\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb = xb.to(device)\n                logits = model(xb).squeeze(-1).cpu()\n                all_logits.append(logits)\n                all_y.append(yb.cpu())\n        logits = torch.cat(all_logits)\n        y = torch.cat(all_y)\n        probs = torch.sigmoid(logits)\n\n        thresholds = torch.linspace(0.05, 0.95, steps=19)\n        best_thr, best_bal = 0.5, -1.0\n        for thr in thresholds:\n            thr_f = float(thr)\n            pred = (probs >= thr_f).to(torch.int64)\n            y_i = y.to(torch.int64)\n            tp = int(((pred==1)&(y_i==1)).sum())\n            fp = int(((pred==1)&(y_i==0)).sum())\n            tn = int(((pred==0)&(y_i==0)).sum())\n            fn = int(((pred==0)&(y_i==1)).sum())\n            precision, recall, f1, specificity = metrics_from_cm(tp, fp, tn, fn)\n            bal = 0.5*(recall+specificity)\n            if bal > best_bal:\n                best_bal, best_thr = bal, thr_f\n        return best_bal, best_thr\n\n    for epoch in range(1, 6):\n        model.train()\n        tr_loss = 0.0\n        n = 0\n        for xb, yb in train_loader:\n            xb = xb.to(device)\n            yb = yb.to(device)\n            opt.zero_grad()\n            logits = model(xb).squeeze(-1)\n            loss = crit(logits, yb)\n            loss.backward()\n            opt.step()\n            tr_loss += loss.item() * xb.size(0)\n            n += xb.size(0)\n        tr_loss /= n\n\n        bal, thr = eval_bal_acc(model)\n        print(f\"epoch {epoch:02d} | train loss {tr_loss:.3f} | val bal acc {bal:.3f} | best thr {thr:.2f}\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## What you should be able to explain after this notebook\n\n- Why `[B, L, C]` becomes `[B, N, P, C]` (Patchify)\n- Why we train on logits using BCEWithLogitsLoss\n- What a confusion matrix is\n- Why we hold out entire sessions (date folders)\n- Why threshold affects precision/recall/specificity\n- Why balanced accuracy is good when both classes matter\n\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "title": "PatchTST Training Walkthrough"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}